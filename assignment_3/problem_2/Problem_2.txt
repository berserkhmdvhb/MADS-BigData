############################################################################################
Big Data Analytics - Assignment 3

Group 3:
    Tom Deckenbrunnen
    Max Sinner
    Hamed Vaheb

Problem 2
############################################################################################
Instructions on how to run our solution

For this problem, we have the following files:
    - launcher.sh: used to launch the scala script on the cluster. You will have to adjust
                    the workdir variable and then use sbatch launcher.sh to run the
                    scala script
    - outlier_mvt.scala: the actual script which is going to be launched. here, you might
                         have to adjust the path to load in the data. The necessary data for
                         the visualisation will be written into a directory called "output",
                         which is going to be split into a raw_sample, a cluster, and an
                         outlier subdirectory. The latter just contains (a) CSV file(s) with
                         the detected outliers, while the former two contain the files for
                         the visualisation.
    - visualise_cluster.py: a python script in which you might have to adjust the paths, too.
                            Upon launching the script, it will ask you what you want to
                            visualise.
    - requirements.txt: list of packages that need to be installed in a virtual environment
                        with pip for the visualisation
    - Problem_2.txt: this file, obviously

Furthermore, it is best to use the following folder structure in order to minimise the
amount of changes needed to be performed for the paths:
    - BDA:
        - Data:
            - gearbox_readings:
                - csvs (contains only the csv files, not the word document!)
        - Assignment_3:
            - Problem_2:
                - launcher.sh
                - outlier_mvt.scala
                - Problem_2.txt
                - visualiser: (also contains the needed virtual environment then)
                    - visualise_cluster.py
                    - requirements.txt

However, it is still recommended to still have a look at the paths and adjust them manually,
ie in the outlier_mvt.scala and the visualise_cluster.py files... 

############################################################################################
Explanations of our approach

The obvious first step was to inspect the raw data. For this, we load the dataset into a
dataframe, add indicative column names, and write a sample, eg. 1% of the total, to csv files,
which we then visualise with the provided visualise_cluster.py script. This gives us a good
idea of what value to expect for the number of clusters k, as the distribution of our data has
the shape of a capital I or a dumbbell, if you will.

After this, we constructed a first attempt of k-means clustering. Once this has worked, we
expanded the pipeline (despite not using a pipeline object explicitly) into a
hyper-parameter tuning for the number of clusters k. Since we are only dealing with numerical
values, we chose not to try cosine distance and stuck with the Euclidean distance. One could
furthermore have tried whether a random initialisation for the centroids might have performed
better than the default k-means||. However, this idea was rejected, too, based on the
distribution. As such, it remained to choose a sensible range of values for k, which, as
suggested by the assignment, was 2 to 10 (1 doesn't make sense, that's just the distribution).

In order to choose the best possible k, some sort of evaluation measure was necessary. It was
looked at different measures, ie: WSSE, silhouette score. However. only the silhouette score
was used in the end since WSSE would have required to be paired with the unreliable elbow
method.
This preliminary tuning revealed that k=2 is, among the tested values, the best possible choice,
with a silhouette score >0.99.
Naturally, higher values, ie. 50, 100, 150, were spot-tested, too, however, all of them resulted
in a negative silhouette score, leading us to abandon higher values for k.

Once the clustering was performed, we had the model predict the corresponding clusters for
every data point. After this, we had to think about a sensible method to actually detect
outliers. For this, we will refer to the following paper:
        Outlier Detection using Improved Genetic K-means
        in International Journal of Computer Applications (2011)
        by M.H. Marghny and Ahmed I. Taloba
We used the idea of outlyingness from this paper. In the paper, the outlyingness factor of 
a point, defined as the ratio of of a point's distance from its centroid and the maximal
distance of any point of that particular centroid. These values are therefore in a range
from 0 to 1, with 0 being the outlyingness of the centroid and 1 being the outlyingness of
the point of that cluster that is the furthest away from the centroid.
Then, we defined a threshold of 0.9 as the threshold for outliers.

Ultimately, these identified outliers are then written to (a) csv file(s). 
############################################################################################
Results and Runtimes
total runtime on the cluster for the script: 13 mins 35 s

While outliers can be detected using this method, it is questionable whether or not k-means
is a good approach to outlier detection for this particular dataset. In general, k-means
performs best when the clusters are spherical in nature, however, this is less straightforward
here. k=3 resulted in a silhouette score of ~0.84, but a visually incomprehensible clustering.
Perhaps, in this case, a Gaussian mixture model might have performed better.